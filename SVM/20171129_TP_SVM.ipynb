{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TP SVM Novembre 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# importer les données\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# afficher la description de la base de données\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# iris.feature_names[]\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SVM à noyau linéaire\n",
    "Nous allons nous limiter pour l'instant à deux classes : setosa et virginica, et à deux features (pour visualiser) : sepal length and sepal width. Nous allons entrainer une SVM linéaire et afficher l'hyperplan séparateur (en 2D une droite donc).\n",
    "\n",
    "Nous allons utiliser la classe [SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) du module svm de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C=1000)\n",
    "\n",
    "# on sélectionne les données voulues (2 classes et 2 features)\n",
    "X = iris.data[iris.target!=1, :2]\n",
    "print(X.shape)\n",
    "y = iris.target[iris.target!=1]\n",
    "print(y.shape)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Représentons l'hyperplan séparateur !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "# plot the decision function\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "# plot support vectors\n",
    "#ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "#           linewidth=1, facecolors='none')\n",
    "\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=30,\n",
    "           linewidth=1, marker='x', color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question :__ Où sont situés les vecteurs de support ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Affichons la performance du prédicteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question :__ Quelle mesure de performance est calculée par `clf.score` ? Référez-vous à la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.score). Que veut dire une performance de 1.0 ?\n",
    "\n",
    "__Réponse :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Considérons maintenant les deux classes Versicolour et Virginica !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1000)\n",
    "\n",
    "# on sélectionne les données voulues (2 classes et 2 features)\n",
    "X = iris.data[iris.target!=0, :2]\n",
    "print(X.shape)\n",
    "y = iris.target[iris.target!=0]\n",
    "print(y.shape)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "# plot the decision function\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "\n",
    "# plot support vectors\n",
    "#ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "#           linewidth=1, facecolors='none')\n",
    "\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=30,\n",
    "           linewidth=1, marker='x', color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Où sont situés les vecteurs de support ?\n",
    "\n",
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la performance de ce modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "La performance n'est que de 0.73. Essayons d'utiliser un noyau pour avoir une séparation plus complexe et mieux coller aux données !\n",
    "\n",
    "### SVM à noyau non linéaire\n",
    "\n",
    "Nous allons utiliser un noyau RBF gaussien, pour plusieurs valeurs du paramètre gamma. En classe nous avons donné la formule \n",
    "$k(x, x') = \\frac{1}{\\sqrt{2 \\pi}} \\exp\\frac{||x - x'||^2}{2 \\sigma^2}$ pour le noyau gaussien. \n",
    "\n",
    "__Question :__ À quoi correspond le paramètre gamma ?\n",
    "\n",
    "__Réponse :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Valeurs de gamma\n",
    "gamma_range = np.linspace(0.1, 50, 20)\n",
    "\n",
    "for param in gamma_range:\n",
    "    clf = svm.SVC(kernel='rbf', C=0.01, gamma=param)\n",
    "    clf.fit(X, y)\n",
    "    print(\"gamma: %.2f\" % param, \"score: %.2f\" % clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Affichez maintenant la frontière de séparation pour le dernier de ces classifieurs, qui a un score de 0.80, et donc nettement meilleur que le modèle linéaire précédent (score = 0.73)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Réponse : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quels points sont vecteurs de supports ? Pensez-vous que le modèle va bien généraliser ?\n",
    "\n",
    "__Réponse :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Est-ce que ce modèle se __généralise__ bien, autrement dit, sera-t-il capable de faire de bonnes prédictions sur de nouvelles données que nous n'avons pas utilisées pour le construire ? \n",
    "\n",
    "Pour le savoir, nous allons séparer les données en un __jeu d'entraînement__ et un __jeu de test__. Nous allons entraîner nos SVMs sur le jeu d'entraînement seulement, et mesurer leur performance sur le jeu de test. Le jeu de test, étant inconnu au moment de l'entraînement, fait figure de nouvelles données. Pour cela nous allons utiliser la fonction `train_test_split` de scikit-learn, décrite [ici](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=56)\n",
    "\n",
    "acc_train, acc_test = list(), list()\n",
    "for param in np.linspace(0.1, 50, 20):\n",
    "    clf = svm.SVC(kernel='rbf', C=0.01, gamma=param)\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc_train.append(clf.score(X_train, y_train))\n",
    "    acc_test.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Afficher le score sur le jeu d'entraînement / le jeu de test pour chaque valeur du paramètre gamma\n",
    "plt.plot(np.linspace(0.1, 50, 20), acc_train, label='train set')\n",
    "plt.plot(np.linspace(0.1, 50, 20), acc_test, label='test set')\n",
    "\n",
    "plt.xlabel(\"Gamma\", fontsize=12)\n",
    "plt.ylabel(\"Performance\", fontsize=12)\n",
    "\n",
    "plt.legend(loc='best', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question : __ Observez-vous un effet de surapprentissage ? Où ? \n",
    "\n",
    "__Réponse :__  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Le graphique ci-dessus nous donne envie de prendre pour le paramètre gamma une valeur proche de 10 ou 20. Mais attention ! Si nous prenons le paramètre qui marche le mieux sur le dataset de test, nous risquons aussi de surapprendre : nous aurons alors utilisé le jeu de test pour choisir le meilleur modèle, autrement dit, nous aurons touché aux données soi-disant inconnuees lors de l'apprentissage...\n",
    "\n",
    "Pour éviter cela, nous allons faire une __validation croisée__ (_cross-validation_) sur le jeu d'entraînement.\n",
    "\n",
    "Nous allons pour cela utiliser la classe [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) du module model_selection de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir les paramètres à tester\n",
    "parameters = {'kernel':('linear', 'rbf'), \n",
    "              'C':[0.1, 1, 10]}\n",
    "\n",
    "# Initialiser un classifieur SVM\n",
    "svc = svm.SVC()\n",
    "\n",
    "# Initialiser une validation croisée\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "\n",
    "# Faire tourner la validation croisée sur le jeu d'entraînement\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(clf.cv_results_['mean_test_score'].reshape(len(parameters['kernel']), \n",
    "                                                      len(parameters['C'])), interpolation='none')\n",
    "\n",
    "plt.xlabel('C', fontsize=14)\n",
    "plt.ylabel('noyau', fontsize=14)\n",
    "plt.title(\"Score\", fontsize=14)\n",
    "\n",
    "plt.xticks(np.arange(len(parameters['C'])), parameters['C'], rotation=45)\n",
    "plt.yticks(np.arange(len(parameters['kernel'])), parameters['kernel'], rotation=45)\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quel est le rôle du paramètre C ? Qu'observez-vous quand C est grand ? \n",
    "\n",
    "__Réponse :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Mise en pratique : sélectionnons les meilleurs paramètres de SVM pour la classification avec les 4 paramètres disponibles\n",
    "\n",
    "__Question :__ Entraînez une SVM de classification pour séparer les données sur les deux problèmes (setosa vs virginica, puis versicolor vs virginica). Entraînez votre SVM en validation croisée sur le jeu d'entraînement. Quels paramètres pouvez-vous faire varier ? \n",
    "\n",
    "Quelle est la performance de votre modèle optimal _sur le jeu de test_ ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 1) Setosa vs virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### 2) Versicolour et Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question bonus :__ Comment construiriez-vous un modèle multi-classe, à base de SVMs, qui assigne une nouvelle observation à une des trois classes setosa, virginica ou versicolor ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
