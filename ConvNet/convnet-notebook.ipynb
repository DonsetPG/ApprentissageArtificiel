{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a été préparé par Fabien Moutarde (MINES ParisTech) en modifiant/combinant 2 notebooks de Cambridge : http://online.cambridgecoding.com/notebooks/cca_admin/deep-learning-for-complete-beginners-recognising-handwritten-digits\n",
    "http://online.cambridgecoding.com/notebooks/cca_admin/convolutional-neural-networks-with-keras\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of this practical session is to get you quickly up to speed with *deep learning*; from first principles, all the way to discussions of some of the intricate details, with the purposes of achieving respectable performance on one established machine learning benchmark: [MNIST](http://yann.lecun.com/exdb/mnist/) (classification of hand-written digits).\n",
    "\n",
    "\n",
    "MNIST hand-written digits dataset                      \n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/mnist.png)  \n",
    "\n",
    "By the end of this part of thi practical session, you should be capable of understanding and producing a simple ConvNet (with a structure similar to LeNet architecture) in Keras, achieving a respectable level of accuracy on MNIST.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convolutions\n",
    "\n",
    "It turns out that there is a very efficient way of pulling this off, and it makes advantage of the structure of the information encoded within an image---it is assumed that pixels that are spatially *closer* together will \"cooperate\" on forming a particular feature of interest much more than ones on opposite corners of the image. Also, if a particular (smaller) feature is found to be of great importance when defining an image's label, it will be equally important if this feature was found anywhere within the image, regardless of location.\n",
    "\n",
    "Enter the **convolution** operator. Given a two-dimensional image, $\\bf I$, and a small matrix, $\\bf K$ of size $h \\times w$, (known as a *convolution kernel*), which we assume encodes a way of extracting an interesting image feature, we compute the convolved image, ${\\bf I} * {\\bf K}$, by overlaying the kernel on top of the image in all possible ways, and recording the sum of elementwise products between the image and the kernel:\n",
    "\n",
    "$$({\\bf I} * {\\bf K})_{xy} = \\sum_{i=1}^h \\sum_{j=1}^w {{\\bf K}_{ij} \\cdot {\\bf I}_{x + i - 1, y + j - 1}}$$\n",
    "\n",
    "(in fact, the exact definition would require us to flip the kernel matrix first, but for the purposes of machine learning it is irrelevant whether this is done)\n",
    "\n",
    "The images below show a diagrammatical overview of the above formula and the result of applying convolution (with two separate kernels) over an image, to act as an edge detector:\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/convolve.png)\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/lena.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional and pooling layers\n",
    "\n",
    "The convolution operator forms the fundamental basis of the **convolutional** layer of a ConvNet. The layer is completely specified by a certain number of kernels, $\\bf \\vec{K}$ (along with additive biases, $\\vec{b}$, per each kernel), and it operates by computing the convolution of the output images of a previous layer with each of those kernels, afterwards adding the biases (one per each output image). Finally, an activation function, $\\sigma$, may be applied to all of the pixels of the output images. Typically, the input to a convolutional layer will have $d$ *channels* (e.g. red/green/blue in the input layer), in which case the kernels are extended to have this number of channels as well, making the final formula of a single output image channel of a convolutional layer (for a kernel ${\\bf K}$ and bias $b$) as follows:\n",
    "\n",
    "$$\\mathrm{conv}({\\bf I}, {\\bf K})_{xy} = \\sigma\\left(b + \\sum_{i=1}^h \\sum_{j=1}^w \\sum_{k=1}^d {{\\bf K}_{ijk} \\cdot {\\bf I}_{x + i - 1, y + j - 1, k}}\\right)$$\n",
    "\n",
    "Note that, since all we're doing here is addition and scaling of the input pixels, the kernels may be learned from a given training dataset via *gradient descent*, exactly as the weights of an MLP. In fact, an MLP is perfectly capable of replicating a convolutional layer, but it would require a lot more training time (and data) to learn to approximate that mode of operation.\n",
    "\n",
    "Finally, let's just note that a convolutional operator is in no way restricted to two-dimensionally structured data: in fact, most machine learning frameworks ([Keras included](https://keras.io/layers/convolutional/)) will provide you with out-of-the-box layers for 1D and 3D convolutions as well!\n",
    "\n",
    "It is important to note that, while a convolutional layer significantly decreases the number of *parameters* compared to a fully connected (FC) layer, it introduces more **hyperparameters**---parameters whose values need to be chosen *before* training starts.\n",
    "\n",
    "Namely, the hyperparameters to choose within a single convolutional layer are:\n",
    "- *depth*: how many different kernels (and biases) will be convolved with the output of the previous layer;\n",
    "- *height* and *width* of each kernel;\n",
    "- *stride*: by how much we shift the kernel in each step to compute the next pixel in the result. This specifies the overlap between individual output pixels, and typically it is set to $1$, corresponding to the formula given before. Note that larger strides result in smaller output sizes.\n",
    "- *padding*: note that convolution by any kernel larger than $1\\times 1$ will *decrease* the output image size---it is often desirable to keep sizes the same, in which case the image is sufficiently padded with zeroes at the edges. This is often called *\"same\"* padding, as opposed to *\"valid\"* (no) padding. It is possible to add arbitrary levels of padding, but typically the padding of choice will be either same or valid.\n",
    "\n",
    "As already hinted, convolutions are not typically meant to be the sole operation in a ConvNet (although there have been promising recent developments on [all-convolutional networks](https://arxiv.org/pdf/1412.6806v3.pdf)); but rather to extract useful features of an image prior to downsampling it sufficiently to be manageable by an MLP.\n",
    "\n",
    "A very popular approach to downsampling is a *pooling* layer, which consumes small and (usually) disjoint chunks of the image (typically $2\\times 2$) and aggregates them into a single value. There are several possible schemes for the aggregation---the most popular being **max-pooling**, where the maximum pixel value within each chunk is taken. A diagrammatical illustration of $2\\times 2$ max-pooling is given below.\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/pool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together: a typical ConvNet architecture\n",
    "\n",
    "Now that we got all the building blocks, let's see what a typical convolutional neural network might look like!\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/cnn.png)\n",
    "\n",
    "A typical ConvNet architecture for a $k$-class image classification can be split into two distinct parts---a chain of repeating $\\mathrm{Conv}\\rightarrow\\mathrm{Pool}$ layers (sometimes with more than one convolutional layer at once), followed by a few fully connected layers (taking each pixel of the computed images as an independent input), culminating in a $k$-way softmax layer, to which a cross-entropy loss is optimised. I did not draw the activation functions here to make the sketch clearer, but do keep in mind that typically after every convolutional or fully connected layer, an activation (e.g. ReLU) will be applied to all of the outputs.\n",
    "\n",
    "Note the effect of a single $\\mathrm{Conv}\\rightarrow\\mathrm{Pool}$ pass through the image: it reduces height and width of the individual channels in favour of their number, i.e. *depth*.\n",
    "\n",
    "The softmax layer and cross-entropy loss are both introduced in more detail [in another tutorial](http://online.cambridgecoding.com/notebooks/cca_admin/deep-learning-for-complete-beginners-recognising-handwritten-digits). For summarisation purposes, a softmax layer's purpose is converting any vector of real numbers into a vector of *probabilities* (nonnegative real values that add up to 1). Within this context, the probabilities correspond to the likelihoods that an input image is a member of a particular class. Minimising the cross-entropy loss has the effect of maximising the model's confidence in the *correct* class, without being concerned for the probabilites for other classes---this makes it a more suitable choice for probabilistic tasks compared to, for example, the squared error loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detour: Overfitting, regularisation and dropout\n",
    "\n",
    "This will be the first (and hopefully the only) time when I will divert your attention to a seemingly unrelated topic. It regards a very important pitfall of machine learning---**overfitting** a model to the training data. While this is primarily going to be a major topic of the next tutorial in the series, the negative effects of overfitting will tend to become quite noticeable on the networks like the one we are about to build, and we need to introduce a way to properly protect ourselves against it, before going any further. Luckily, there is a very simple technique we can use.\n",
    "\n",
    "Overfitting corresponds to adapting our model to the training set to such extremes that its generalisation potential (performance on samples outside of the training set) is *severely* limited. In other words, our model might have learned the training set (along with any noise present within it) perfectly, but it has failed to capture the underlying process that generated it. To illustrate, consider a problem of fitting a sine curve, with white additive noise applied to the data points: \n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/plotsin.png)\n",
    "\n",
    "Here we have a training set (denoted by blue circles) derived from the original sine wave, along with some noise. If we fit a degree-3 polynomial to this data, we get a fairly good approximation to the original curve. Someone might argue that a degree-14 polynomial would do better; indeed, given we have 15 points, such a fit would *perfectly* describe the training data. However, in this case, the additional parameters of the model cause catastrophic results: to cope with the inherent noise of the data, anywhere except in the closest vicinity of the training points, our fit is completely off.\n",
    "\n",
    "Deep convolutional neural networks have a large number of parameters, especially in the fully connected layers. Overfitting might often manifest in the following form: if we don't have sufficiently many training examples, a small group of neurons might become responsible for doing most of the processing and other neurons becoming redundant; or in the other extreme, some neurons might actually become detrimental to performance, with several other neurons of their layer ending up doing nothing else but correcting for their errors.\n",
    "\n",
    "To help our models generalise better in these circumstances, we introduce techniques of *regularisation*: rather than reducing the number of parameters, we impose *constraints* on the model parameters during training to keep them from learning the noise in the training data. The particular method I will introduce here is **dropout**---a technique that initially might seem like \"dark magic\", but actually helps to eliminate exactly the failure modes described above. Namely, dropout with parameter $p$ will, within a single training iteration, go through all neurons in a particular layer and, with probability $p$, *completely eliminate them from the network throughout the iteration*. This has the effect of forcing the neural network to cope with *failures*, and not to rely on existence of a particular neuron (or set of neurons)---relying more on a *consensus* of several neurons within a layer. This is a very simple technique that works quite well already for combatting overfitting on its own, without introducing further regularisers. An illustration is given below.\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/drop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a deep ConvNet to MNIST\n",
    "\n",
    "As this post's objective, we will implement a deep convolutional neural network---and apply it on the MNIST digit recognition classification task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned, a ConvNet will typically have more hyperparameters than an MLP. For the purposes of this tutorial practical session, we will also stick to \"sensible\" hand-picked values for them, but do still keep in mind that later on I will introduce a more proper method for learning them.\n",
    "\n",
    "The hyperparameters are:\n",
    "- The *batch size*, representing the number of training examples being used simultaneously during a single iteration of the gradient descent algorithm;\n",
    "- The number of *epochs*, representing the number of times the training algorithm will iterate over the entire training set before terminating\\*;\n",
    "- The *kernel sizes* in the convolutional layers;\n",
    "- The *pooling size* in the pooling layers;\n",
    "- The *number of kernels* in the convolutional layers;\n",
    "- The *dropout probability* (we will apply dropout after each pooling, and after the fully connected layer);\n",
    "- The *number of neurons* in the fully connected layer of the MLP.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling time! Our network has an architecture similar to LeNet5 of LeCun (see figure below). It will consist of two consecutive groups of one `Convolution2D` followed by  a `MaxPooling2D` layer. After the first pooling layer, the number of kernels is rougly doubled (in line with the previously mentioned principle of sacrificing height and width for more depth). Afterwards, the output of the second pooling layer is flattened to 1D (via the `Flatten` layer), and passed through one or two fully connected (`Dense`) layers. ReLU activations will once again be used for all layers except the output dense layer, which will use a softmax activation (for purposes of probabilistic classification).\n",
    "\n",
    "![](http://perso.mines-paristech.fr/fabien.moutarde/ES_MachineLearning/TP_convNets/lenet5.png)\n",
    "\n",
    "To regularise our model, a `Dropout` layer is applied after each pooling layer, and after the first `Dense` layer. This is another area where Keras shines compared to other frameworks: it has an internal flag that automatically enables or disables dropout, depending on whether the model is currently used for training or testing.\n",
    "\n",
    "The remainder of the model specification is the following:\n",
    "- We use the *cross-entropy* loss function as the objective to optimise (as its derivation is more appropriate for probabilistic tasks);\n",
    "- We use the [*Adam* optimiser for gradient descent](http://sebastianruder.com/optimizing-gradient-descent/);\n",
    "- We report the *accuracy* of the model (as the dataset is balanced across the ten classes)\\*;\n",
    "- We hold out a significant proportion of the data for validation purposes.\n",
    "\n",
    "\\* To get a feeling for why accuracy might be inappropriate for unbalanced datasets, consider an extreme case where 90% of the test data belongs to class $x$ (this could be, for example, the task of diagnosing patients for an extremely rare disease). In this case, a classifier that just outputs $x$ achieves a seemingly impressive accuracy of 90% on the test data, without really doing any learning/generalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, possibly after some tweaking of its architectural parameters, should be able to break $99\\%$ accuracy on its **test set** with little to no effort.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Throughout this post we have covered the essentials of convolutional neural networks, introduced the problem of overfitting, and made a very brief dent into how it could be rectified via regularisation (by applying dropout) and successfully implemented a two-layer deep ConvNet (with LeNet like architecture) in Keras, applying it to MNIST, all in under 50 lines of code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just show me the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulgarnier/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version tensorflow :1.11.0\n",
      "Version KERAS :2.2.4\n",
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "(60000, 1, 28, 28)\n",
      "(60000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulgarnier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:72: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (5, 5), activation=\"relu\", data_format=\"channels_first\", input_shape=(1, 28, 28..., padding=\"same\")`\n",
      "/Users/paulgarnier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), activation=\"relu\", padding=\"same\")`\n",
      "/Users/paulgarnier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:100: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0xb22e14be0>>\n",
      "Train on 24000 samples, validate on 36000 samples\n",
      "Epoch 1/13\n",
      "24000/24000 [==============================] - 24s 1ms/step - loss: 0.3759 - acc: 0.8887 - val_loss: 0.1724 - val_acc: 0.9486\n",
      "Epoch 2/13\n",
      "24000/24000 [==============================] - 24s 997us/step - loss: 0.1395 - acc: 0.9558 - val_loss: 0.1197 - val_acc: 0.9634\n",
      "Epoch 3/13\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.1001 - acc: 0.9698 - val_loss: 0.1204 - val_acc: 0.9631\n",
      "Epoch 4/13\n",
      "24000/24000 [==============================] - 24s 992us/step - loss: 0.0807 - acc: 0.9741 - val_loss: 0.1220 - val_acc: 0.9607\n",
      "Epoch 5/13\n",
      "24000/24000 [==============================] - 24s 1ms/step - loss: 0.0663 - acc: 0.9797 - val_loss: 0.0871 - val_acc: 0.9739\n",
      "Epoch 6/13\n",
      "23936/24000 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9818"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-49fec0b36e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m history = model.fit(X_train, Y_train, # Train the model using the training set...\n\u001b[1;32m     99\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m           verbose=1, validation_split=0.6) # ...holding out 40% of the data for validation\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# EVALUATE THE MODEL ON TEST SET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "# FIRST CHOOSE WHICH \"BACK-END\" YOU WILL USE, BETWEEN tensorflow (preferable) OR theano\n",
    "#    (depending on which you have managed to install)\n",
    "os.environ['KERAS_BACKEND']=\"tensorflow\"\n",
    "import tensorflow\n",
    "print(\"Version tensorflow :\" + tensorflow.__version__)\n",
    "#os.environ['KERAS_BACKEND']=\"theano\"\n",
    "#import theano\n",
    "#print(\"Version Theano :\" + theano.__version__)\n",
    "\n",
    "\n",
    "# WHATEVER BACK-END YOU HAVE CHOSEN, YOU SHALL USE keras AS RONT-END\n",
    "import keras\n",
    "print(\"Version KERAS :\" + keras.__version__)\n",
    "\n",
    "from keras.datasets import mnist # subroutines for fetching the MNIST dataset\n",
    "from keras.models import Model, Sequential # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "\n",
    "\n",
    "\n",
    "# CONVNET PARAMETERS\n",
    "# ===================\n",
    "batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
    "num_epochs = 13 # we iterate ?? times over the entire training set\n",
    "kernel_size = 5 # we will use 5x5 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 6 # we will initially have 6 kernels in first conv. layer...\n",
    "conv_depth_2 = 16 # ...switching to 16 after the first pooling layer\n",
    "drop_prob_1 = 0.# dropout after pooling with probability ??\n",
    "drop_prob_2 = 0. # dropout in the FC layer with probability ??\n",
    "hidden_size = 128 # the FC layer will have 128 neurons\n",
    "weight_penalty = 0.0 # Factor for weights penalty\n",
    "\n",
    "\n",
    "\n",
    "# DATASET CHARACTERISTICS\n",
    "num_train = 60000 # there are 60000 training examples in MNIST\n",
    "num_test = 10000 # there are 10000 test examples in MNIST\n",
    "height, width, depth = 28, 28, 1 # MNIST images are 28x28 and *greyscale*\n",
    "num_classes = 10 # there are 10 classes (1 per digit)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # fetch MNIST data\n",
    "\n",
    "# REFORMAT PROPERLY THE DATA\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 # Normalise data to [0, 1] range\n",
    "X_test /= 255 # Normalise data to [0, 1] range\n",
    "X_train = X_train[:, newaxis, :, :] # Reshape in \"convolutionable\" format (add tensor dim for the depth)\n",
    "X_test = X_test[:, newaxis, :, :] # Reshape in \"convolutionable\" format (add tensor dim for the depth)\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# NOW, BUILD THE MODEL ARCHITECTURE\n",
    "# =================================\n",
    "\n",
    "model = Sequential()\n",
    "# FIRST CONVOLUTION+POOLING LAYERS\n",
    "#   Conv [8] -> Pool (with dropout on the pooling layer)\n",
    "model.add( Conv2D(conv_depth_1, (kernel_size,kernel_size), padding='same', activation='relu', \n",
    "                         data_format=\"channels_first\", input_shape=( 1, 28, 28)) )\n",
    "model.add( MaxPooling2D(pool_size=(pool_size, pool_size)) )\n",
    "model.add( Dropout(drop_prob_1) ) # Some Dropout regularization (if necessary)\n",
    "\n",
    "# FIRST CONVOLUTION+POOLING LAYERS\n",
    "#    Conv [16] -> Pool (with dropout on the pooling layer)\n",
    "model.add( Conv2D(conv_depth_2, (kernel_size,kernel_size), padding='same', activation='relu') )\n",
    "model.add( MaxPooling2D(pool_size=(pool_size, pool_size)) )\n",
    "model.add( Dropout(drop_prob_1) ) # Some Dropout regularization (if necessary)\n",
    "\n",
    "# CLASSIFICATION PART: FULLY-CONNECTED LAYER + OUTPUT LAYER\n",
    "#   Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "model.add( Flatten() )\n",
    "model.add( Dense(hidden_size, activation='relu', kernel_regularizer=regularizers.l2(weight_penalty)) )\n",
    "model.add( Dropout(drop_prob_2) ) # Some Dropout regularization (if necessary)\n",
    "model.add( Dense(num_classes, activation='softmax') )\n",
    "\n",
    "# DISPLAY THE MODEL ARCHITECTURE INFORMATION\n",
    "print(model.summary)\n",
    "\n",
    "# DEFINE THE LOSS FUNCTION AND OPTIMIZER\n",
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "# TRAIN THE MODEL\n",
    "history = model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=num_epochs,\n",
    "          verbose=1, validation_split=0.6) # ...holding out 40% of the data for validation\n",
    "\n",
    "# EVALUATE THE MODEL ON TEST SET\n",
    "print(\"\\n EVALUATION [loss, accuracy] on TEST set:\")\n",
    "model.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the training history, in order to check if overfitting seems to have occured or not, and if more training epochs could be performed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy by epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'valid'], loc='right')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You should see that over-fitting begins to occur.<br> \n",
    "Question 1: WHAT IS THE SIGN OF OVER-FITTING ON ABOVE GRAPH?<br>\n",
    "Answer: <br>\n",
    "<br>\n",
    "There are 2 different methods that can be used to prevent over-fitting.<br>\n",
    "Question 2: WHAT ARE THOSE 2 OVER-FITTING PREVENTION METHODS?<br>\n",
    "Answer :<br>\n",
    "<br>\n",
    "Test those 2 methods SEPARATELY below, by copy-pasting the original code, modifying it, and running it. <br>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final assignment: in code cell below, by applying a good combination and parameterization of the 2 regularization techniques, + increasing the number of training epochs, + reducing the proportion of validation hold-out, TRY TO OBTAIN >99% acuracy ON TEST SET:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve 98.91% accuracy with the following parameters : \n",
    "\n",
    "Nb_epochs : 30+10+30, Dropout_rate_1: 0.4, Dropout_rate_2 : 0.4, Weight_penalty: 0.001, Validation_split : 0.01\n",
    "\n",
    "(we trained the networks 3 times)\n",
    "\n",
    "__\n",
    "\n",
    "After that, I also trained the network one more time, by adding a stopping condition when acc. > 99%\n",
    "\n",
    "However, we achieve xx.xx% accuracy with the last network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version tensorflow :1.11.0\n",
      "Version KERAS :2.2.4\n",
      "Parameters \n",
      "Nb_epochs : 50, Dropout_rate_1: 0.4, Dropout_rate_2 : 0.4, Weight_penalty: 0.001, Validation_split : 0.01\n",
      "Checking the shape of our train set : \n",
      "(60000, 1, 28, 28)\n",
      "(60000, 10)\n",
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0xb471ef940>>\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/50\n",
      "59400/59400 [==============================] - 42s 709us/step - loss: 0.6293 - acc: 0.8319 - val_loss: 0.2518 - val_acc: 0.9700\n",
      "Epoch 2/50\n",
      "59400/59400 [==============================] - 42s 701us/step - loss: 0.3183 - acc: 0.9270 - val_loss: 0.2090 - val_acc: 0.9767\n",
      "Epoch 3/50\n",
      "59400/59400 [==============================] - 41s 683us/step - loss: 0.2641 - acc: 0.9386 - val_loss: 0.2056 - val_acc: 0.9700\n",
      "Epoch 4/50\n",
      "59400/59400 [==============================] - 41s 684us/step - loss: 0.2439 - acc: 0.9433 - val_loss: 0.1879 - val_acc: 0.9717\n",
      "Epoch 5/50\n",
      "59400/59400 [==============================] - 42s 709us/step - loss: 0.2335 - acc: 0.9450 - val_loss: 0.1974 - val_acc: 0.9733\n",
      "Epoch 6/50\n",
      "59400/59400 [==============================] - 41s 685us/step - loss: 0.2277 - acc: 0.9475 - val_loss: 0.1888 - val_acc: 0.9767\n",
      "Epoch 7/50\n",
      "59400/59400 [==============================] - 41s 693us/step - loss: 0.2209 - acc: 0.9486 - val_loss: 0.1813 - val_acc: 0.9800\n",
      "Epoch 8/50\n",
      "59400/59400 [==============================] - 43s 724us/step - loss: 0.2169 - acc: 0.9497 - val_loss: 0.1882 - val_acc: 0.9783\n",
      "Epoch 9/50\n",
      "59400/59400 [==============================] - 43s 731us/step - loss: 0.2127 - acc: 0.9502 - val_loss: 0.1699 - val_acc: 0.9850\n",
      "Epoch 10/50\n",
      "59400/59400 [==============================] - 41s 687us/step - loss: 0.2099 - acc: 0.9521 - val_loss: 0.1693 - val_acc: 0.9833\n",
      "Epoch 11/50\n",
      "59400/59400 [==============================] - 41s 682us/step - loss: 0.2088 - acc: 0.9518 - val_loss: 0.1645 - val_acc: 0.9800\n",
      "Epoch 12/50\n",
      "59400/59400 [==============================] - 40s 680us/step - loss: 0.2049 - acc: 0.9535 - val_loss: 0.1622 - val_acc: 0.9833\n",
      "Epoch 13/50\n",
      "59400/59400 [==============================] - 42s 711us/step - loss: 0.2037 - acc: 0.9528 - val_loss: 0.1801 - val_acc: 0.9783\n",
      "Epoch 14/50\n",
      "59400/59400 [==============================] - 43s 724us/step - loss: 0.1995 - acc: 0.9551 - val_loss: 0.1792 - val_acc: 0.9817\n",
      "Epoch 15/50\n",
      "59400/59400 [==============================] - 49s 820us/step - loss: 0.1967 - acc: 0.9539 - val_loss: 0.1718 - val_acc: 0.9800\n",
      "Epoch 16/50\n",
      "59400/59400 [==============================] - 50s 844us/step - loss: 0.2027 - acc: 0.9533 - val_loss: 0.1805 - val_acc: 0.9800\n",
      "Epoch 17/50\n",
      "59400/59400 [==============================] - 46s 782us/step - loss: 0.1994 - acc: 0.9544 - val_loss: 0.1726 - val_acc: 0.9867\n",
      "Epoch 18/50\n",
      "59400/59400 [==============================] - 42s 713us/step - loss: 0.1984 - acc: 0.9552 - val_loss: 0.1692 - val_acc: 0.9800\n",
      "Epoch 19/50\n",
      "59400/59400 [==============================] - 48s 804us/step - loss: 0.1968 - acc: 0.9551 - val_loss: 0.1694 - val_acc: 0.9817\n",
      "Epoch 20/50\n",
      "59400/59400 [==============================] - 47s 785us/step - loss: 0.1990 - acc: 0.9544 - val_loss: 0.1711 - val_acc: 0.9850\n",
      "Epoch 21/50\n",
      "59400/59400 [==============================] - 47s 786us/step - loss: 0.1951 - acc: 0.9554 - val_loss: 0.1729 - val_acc: 0.9850\n",
      "Epoch 22/50\n",
      "59400/59400 [==============================] - 41s 695us/step - loss: 0.1957 - acc: 0.9561 - val_loss: 0.1764 - val_acc: 0.9800\n",
      "Epoch 23/50\n",
      "59400/59400 [==============================] - 43s 720us/step - loss: 0.1930 - acc: 0.9574 - val_loss: 0.1789 - val_acc: 0.9750\n",
      "Epoch 24/50\n",
      "59400/59400 [==============================] - 43s 726us/step - loss: 0.1910 - acc: 0.9573 - val_loss: 0.1797 - val_acc: 0.9783\n",
      "Epoch 25/50\n",
      "59400/59400 [==============================] - 41s 693us/step - loss: 0.1954 - acc: 0.9560 - val_loss: 0.1653 - val_acc: 0.9817\n",
      "Epoch 26/50\n",
      "59400/59400 [==============================] - 46s 772us/step - loss: 0.1916 - acc: 0.9574 - val_loss: 0.1665 - val_acc: 0.9817\n",
      "Epoch 27/50\n",
      "59400/59400 [==============================] - 52s 880us/step - loss: 0.1899 - acc: 0.9572 - val_loss: 0.1832 - val_acc: 0.9767\n",
      "Epoch 28/50\n",
      "59400/59400 [==============================] - 44s 738us/step - loss: 0.1901 - acc: 0.9565 - val_loss: 0.1682 - val_acc: 0.9800\n",
      "Epoch 29/50\n",
      "59400/59400 [==============================] - 43s 725us/step - loss: 0.1912 - acc: 0.9566 - val_loss: 0.1699 - val_acc: 0.9800\n",
      "Epoch 30/50\n",
      "59400/59400 [==============================] - 43s 722us/step - loss: 0.1898 - acc: 0.9573 - val_loss: 0.1717 - val_acc: 0.9800\n",
      "Epoch 31/50\n",
      "59400/59400 [==============================] - 42s 700us/step - loss: 0.1940 - acc: 0.9562 - val_loss: 0.1749 - val_acc: 0.9800\n",
      "Epoch 32/50\n",
      "59400/59400 [==============================] - 42s 701us/step - loss: 0.1865 - acc: 0.9577 - val_loss: 0.1778 - val_acc: 0.9833\n",
      "Epoch 33/50\n",
      "59400/59400 [==============================] - 42s 703us/step - loss: 0.1914 - acc: 0.9571 - val_loss: 0.1663 - val_acc: 0.9800\n",
      "Epoch 34/50\n",
      "59400/59400 [==============================] - 41s 687us/step - loss: 0.1897 - acc: 0.9572 - val_loss: 0.1760 - val_acc: 0.9750\n",
      "Epoch 35/50\n",
      "59400/59400 [==============================] - 42s 703us/step - loss: 0.1902 - acc: 0.9578 - val_loss: 0.1644 - val_acc: 0.9850\n",
      "Epoch 36/50\n",
      "59400/59400 [==============================] - 43s 725us/step - loss: 0.1915 - acc: 0.9570 - val_loss: 0.1638 - val_acc: 0.9867\n",
      "Epoch 37/50\n",
      "59400/59400 [==============================] - 42s 706us/step - loss: 0.1899 - acc: 0.9565 - val_loss: 0.1708 - val_acc: 0.9833\n",
      "Epoch 38/50\n",
      "59400/59400 [==============================] - 44s 741us/step - loss: 0.1889 - acc: 0.9578 - val_loss: 0.1732 - val_acc: 0.9800\n",
      "Epoch 39/50\n",
      "59400/59400 [==============================] - 44s 735us/step - loss: 0.1869 - acc: 0.9590 - val_loss: 0.1626 - val_acc: 0.9817\n",
      "Epoch 40/50\n",
      "59400/59400 [==============================] - 46s 773us/step - loss: 0.1864 - acc: 0.9584 - val_loss: 0.1598 - val_acc: 0.9817\n",
      "Epoch 41/50\n",
      "59400/59400 [==============================] - 45s 753us/step - loss: 0.1888 - acc: 0.9580 - val_loss: 0.1633 - val_acc: 0.9867\n",
      "Epoch 42/50\n",
      "59400/59400 [==============================] - 43s 730us/step - loss: 0.1872 - acc: 0.9578 - val_loss: 0.1513 - val_acc: 0.9867\n",
      "Epoch 43/50\n",
      "59400/59400 [==============================] - 43s 718us/step - loss: 0.1881 - acc: 0.9570 - val_loss: 0.1702 - val_acc: 0.9800\n",
      "Epoch 44/50\n",
      "59400/59400 [==============================] - 44s 740us/step - loss: 0.1899 - acc: 0.9580 - val_loss: 0.1573 - val_acc: 0.9783\n",
      "Epoch 45/50\n",
      "59400/59400 [==============================] - 43s 716us/step - loss: 0.1856 - acc: 0.9585 - val_loss: 0.1626 - val_acc: 0.9800\n",
      "Epoch 46/50\n",
      "59400/59400 [==============================] - 43s 718us/step - loss: 0.1898 - acc: 0.9572 - val_loss: 0.1659 - val_acc: 0.9833\n",
      "Epoch 47/50\n",
      "59400/59400 [==============================] - 44s 739us/step - loss: 0.1855 - acc: 0.9581 - val_loss: 0.1764 - val_acc: 0.9817\n",
      "Epoch 48/50\n",
      "59400/59400 [==============================] - 42s 707us/step - loss: 0.1855 - acc: 0.9582 - val_loss: 0.1691 - val_acc: 0.9750\n",
      "Epoch 49/50\n",
      "59400/59400 [==============================] - 43s 724us/step - loss: 0.1866 - acc: 0.9582 - val_loss: 0.1549 - val_acc: 0.9850\n",
      "Epoch 50/50\n",
      "59400/59400 [==============================] - 44s 739us/step - loss: 0.1897 - acc: 0.9566 - val_loss: 0.1593 - val_acc: 0.9783\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 5s 466us/step\n",
      "[0.10076899698972702, 0.9827]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# FIRST CHOOSE WHICH \"BACK-END\" YOU WILL USE, BETWEEN tensorflow (preferable) OR theano\n",
    "#    (depending on which you have managed to install)\n",
    "os.environ['KERAS_BACKEND']=\"tensorflow\"\n",
    "import tensorflow\n",
    "print(\"Version tensorflow :\" + tensorflow.__version__)\n",
    "#os.environ['KERAS_BACKEND']=\"theano\"\n",
    "#import theano\n",
    "#print(\"Version Theano :\" + theano.__version__)\n",
    "\n",
    "\n",
    "# WHATEVER BACK-END YOU HAVE CHOSEN, YOU SHALL USE keras AS RONT-END\n",
    "import keras\n",
    "print(\"Version KERAS :\" + keras.__version__)\n",
    "\n",
    "from keras.datasets import mnist # subroutines for fetching the MNIST dataset\n",
    "from keras.models import Model, Sequential # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import History \n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "\n",
    "# New Parameters \n",
    "# ==============\n",
    "num_epochs = 50 # we iterate 50 times over the entire training set\n",
    "# Regul : \n",
    "\n",
    "# usual values, but here it seems to be a bit too high.\n",
    "#drop_prob_1 = #0.5# dropout after pooling with probability 1/2\n",
    "#drop_prob_2 = #0.6 # dropout in the FC layer with probability 0.6\n",
    "#weight_penalty = 0.03 # Factor for weights penalty\n",
    "\n",
    "## \n",
    "\n",
    "drop_prob_1 = 0.4# dropout after pooling with probability 0.2\n",
    "drop_prob_2 = 0.4 # dropout in the FC layer with probability 0.3\n",
    "weight_penalty = 0.001 # Factor for weights penalty\n",
    "\n",
    "validation_proba = 0.01 # validation = 600 / 60 000 \n",
    "\n",
    "print(\"Parameters \")\n",
    "print(\"Nb_epochs : {}, Dropout_rate_1: {}, Dropout_rate_2 : {}, Weight_penalty: {}, Validation_split : {}\"\n",
    "                    .format(num_epochs,drop_prob_1,drop_prob_2,weight_penalty,validation_proba))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CONVNET PARAMETERS\n",
    "# ===================\n",
    "batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
    "kernel_size = 5 # we will use 5x5 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 8 # we will initially have 8 kernels in first conv. layer...\n",
    "conv_depth_2 = 16 # ...switching to 16 after the first pooling layer\n",
    "hidden_size = 128 # the FC layer will have 128 neurons\n",
    "\n",
    "\n",
    "\n",
    "# DATASET CHARACTERISTICS\n",
    "num_train = 60000 # there are 60000 training examples in MNIST\n",
    "height, width, depth = 28, 28, 1 # MNIST images are 28x28 and *greyscale*\n",
    "num_classes = 10 # there are 10 classes (1 per digit)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # fetch MNIST data\n",
    "\n",
    "# REFORMAT PROPERLY THE DATA\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 # Normalise data to [0, 1] range\n",
    "X_test /= 255 # Normalise data to [0, 1] range\n",
    "X_train = X_train[:, newaxis, :, :] # Reshape in \"convolutionable\" format (add tensor dim for the depth)\n",
    "X_test = X_test[:, newaxis, :, :] # Reshape in \"convolutionable\" format (add tensor dim for the depth)\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
    "print(\"Checking the shape of our train set : \")\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "\n",
    "# NOW, BUILD THE MODEL ARCHITECTURE\n",
    "# =================================\n",
    "\n",
    "model = Sequential()\n",
    "# FIRST CONVOLUTION+POOLING LAYERS\n",
    "#   Conv [8] -> Pool (with dropout on the pooling layer)\n",
    "model.add( Conv2D(conv_depth_1, (kernel_size,kernel_size), padding='same', activation='relu', \n",
    "                         data_format=\"channels_first\", input_shape=( 1, 28, 28)) )\n",
    "model.add( MaxPooling2D(pool_size=(pool_size, pool_size)) )\n",
    "model.add( Dropout(drop_prob_1) ) # Some Dropout regularization (if necessary)\n",
    "\n",
    "# FIRST CONVOLUTION+POOLING LAYERS\n",
    "#    Conv [16] -> Pool (with dropout on the pooling layer)\n",
    "model.add( Conv2D(conv_depth_2, (kernel_size,kernel_size), padding='same', activation='relu') )\n",
    "model.add( MaxPooling2D(pool_size=(pool_size, pool_size)) )\n",
    "model.add( Dropout(drop_prob_1) ) # Some Dropout regularization (if necessary)\n",
    "\n",
    "# CLASSIFICATION PART: FULLY-CONNECTED LAYER + OUTPUT LAYER\n",
    "#   Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "model.add( Flatten() )\n",
    "model.add( Dense(hidden_size, activation='relu', kernel_regularizer=regularizers.l2(weight_penalty)) )\n",
    "model.add( Dropout(drop_prob_2) ) # Some Dropout regularization (if necessary)\n",
    "model.add( Dense(num_classes, activation='softmax') )\n",
    "\n",
    "# DISPLAY THE MODEL ARCHITECTURE INFORMATION\n",
    "print(model.summary)\n",
    "\n",
    "# DEFINE THE LOSS FUNCTION AND OPTIMIZER\n",
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "# TRAIN THE MODEL\n",
    "\n",
    "history = model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=num_epochs,shuffle =True,\n",
    "          verbose=1, validation_split=validation_proba) # ...holding out 10% of the data for validation\n",
    "\n",
    "# EVALUATE THE MODEL ON TEST SET\n",
    "   \n",
    "print(\"\\n EVALUATION [loss, accuracy] on TEST set:\")\n",
    "lossAndAcc = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(lossAndAcc) # Evaluate the trained model on the test set!\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a few more epochs to try to get 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/10\n",
      "59400/59400 [==============================] - 44s 735us/step - loss: 0.1793 - acc: 0.9607 - val_loss: 0.1579 - val_acc: 0.9883\n",
      "Epoch 2/10\n",
      "59400/59400 [==============================] - 40s 680us/step - loss: 0.1815 - acc: 0.9594 - val_loss: 0.1529 - val_acc: 0.9867\n",
      "Epoch 3/10\n",
      "59400/59400 [==============================] - 41s 682us/step - loss: 0.1814 - acc: 0.9592 - val_loss: 0.1510 - val_acc: 0.9867\n",
      "Epoch 4/10\n",
      "59400/59400 [==============================] - 41s 698us/step - loss: 0.1816 - acc: 0.9595 - val_loss: 0.1564 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "59400/59400 [==============================] - 40s 677us/step - loss: 0.1766 - acc: 0.9610 - val_loss: 0.1382 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "59400/59400 [==============================] - 40s 676us/step - loss: 0.1778 - acc: 0.9613 - val_loss: 0.1638 - val_acc: 0.9783\n",
      "Epoch 7/10\n",
      "59400/59400 [==============================] - 41s 697us/step - loss: 0.1753 - acc: 0.9618 - val_loss: 0.1670 - val_acc: 0.9817\n",
      "Epoch 8/10\n",
      "59400/59400 [==============================] - 40s 676us/step - loss: 0.1782 - acc: 0.9601 - val_loss: 0.1581 - val_acc: 0.9800\n",
      "Epoch 9/10\n",
      "59400/59400 [==============================] - 40s 676us/step - loss: 0.1785 - acc: 0.9606 - val_loss: 0.1544 - val_acc: 0.9850\n",
      "Epoch 10/10\n",
      "59400/59400 [==============================] - 41s 696us/step - loss: 0.1792 - acc: 0.9598 - val_loss: 0.1604 - val_acc: 0.9833\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 359us/step\n",
      "[0.09250915004611016, 0.9876]\n"
     ]
    }
   ],
   "source": [
    "new_num_epochs = 40 - 30\n",
    "\n",
    "history = model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=new_num_epochs,shuffle =True,\n",
    "          verbose=1, validation_split=validation_proba) # ...holding out 10% of the data for validation\n",
    "\n",
    "# EVALUATE THE MODEL ON TEST SET\n",
    "   \n",
    "print(\"\\n EVALUATION [loss, accuracy] on TEST set:\")\n",
    "lossAndAcc = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(lossAndAcc) # Evaluate the trained model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "59400/59400 [==============================] - 44s 733us/step - loss: 0.1761 - acc: 0.9614 - val_loss: 0.1719 - val_acc: 0.9883\n",
      "Epoch 2/30\n",
      "59400/59400 [==============================] - 41s 690us/step - loss: 0.1782 - acc: 0.9606 - val_loss: 0.1666 - val_acc: 0.9867\n",
      "Epoch 3/30\n",
      "59400/59400 [==============================] - 40s 675us/step - loss: 0.1769 - acc: 0.9612 - val_loss: 0.1626 - val_acc: 0.9867\n",
      "Epoch 4/30\n",
      "59400/59400 [==============================] - 43s 727us/step - loss: 0.1780 - acc: 0.9601 - val_loss: 0.1724 - val_acc: 0.9800\n",
      "Epoch 5/30\n",
      "59400/59400 [==============================] - 40s 680us/step - loss: 0.1748 - acc: 0.9606 - val_loss: 0.1729 - val_acc: 0.9883\n",
      "Epoch 6/30\n",
      "59400/59400 [==============================] - 40s 673us/step - loss: 0.1779 - acc: 0.9605 - val_loss: 0.1480 - val_acc: 0.9883\n",
      "Epoch 7/30\n",
      "59400/59400 [==============================] - 42s 700us/step - loss: 0.1768 - acc: 0.9605 - val_loss: 0.1641 - val_acc: 0.9883\n",
      "Epoch 8/30\n",
      "59400/59400 [==============================] - 40s 675us/step - loss: 0.1761 - acc: 0.9602 - val_loss: 0.1688 - val_acc: 0.9867\n",
      "Epoch 9/30\n",
      "59400/59400 [==============================] - 40s 677us/step - loss: 0.1767 - acc: 0.9617 - val_loss: 0.1635 - val_acc: 0.9867\n",
      "Epoch 10/30\n",
      "59400/59400 [==============================] - 41s 698us/step - loss: 0.1765 - acc: 0.9607 - val_loss: 0.1670 - val_acc: 0.9850\n",
      "Epoch 11/30\n",
      "59400/59400 [==============================] - 40s 673us/step - loss: 0.1774 - acc: 0.9603 - val_loss: 0.1579 - val_acc: 0.9867\n",
      "Epoch 12/30\n",
      "59400/59400 [==============================] - 40s 674us/step - loss: 0.1734 - acc: 0.9621 - val_loss: 0.1635 - val_acc: 0.9783\n",
      "Epoch 13/30\n",
      "59400/59400 [==============================] - 41s 695us/step - loss: 0.1790 - acc: 0.9605 - val_loss: 0.1519 - val_acc: 0.9883\n",
      "Epoch 14/30\n",
      "59400/59400 [==============================] - 40s 676us/step - loss: 0.1757 - acc: 0.9609 - val_loss: 0.1531 - val_acc: 0.9883\n",
      "Epoch 15/30\n",
      "59400/59400 [==============================] - 40s 682us/step - loss: 0.1718 - acc: 0.9618 - val_loss: 0.1573 - val_acc: 0.9867\n",
      "Epoch 16/30\n",
      "59400/59400 [==============================] - 41s 695us/step - loss: 0.1804 - acc: 0.9597 - val_loss: 0.1446 - val_acc: 0.9867\n",
      "Epoch 17/30\n",
      "59400/59400 [==============================] - 40s 680us/step - loss: 0.1746 - acc: 0.9623 - val_loss: 0.1625 - val_acc: 0.9850\n",
      "Epoch 18/30\n",
      "59400/59400 [==============================] - 46s 772us/step - loss: 0.1752 - acc: 0.9615 - val_loss: 0.1552 - val_acc: 0.9817\n",
      "Epoch 19/30\n",
      "59400/59400 [==============================] - 42s 708us/step - loss: 0.1775 - acc: 0.9605 - val_loss: 0.1562 - val_acc: 0.9833\n",
      "Epoch 20/30\n",
      "59400/59400 [==============================] - 40s 676us/step - loss: 0.1764 - acc: 0.9607 - val_loss: 0.1494 - val_acc: 0.9867\n",
      "Epoch 21/30\n",
      "59400/59400 [==============================] - 40s 679us/step - loss: 0.1747 - acc: 0.9613 - val_loss: 0.1483 - val_acc: 0.9833\n",
      "Epoch 22/30\n",
      "59400/59400 [==============================] - 42s 701us/step - loss: 0.1772 - acc: 0.9609 - val_loss: 0.1564 - val_acc: 0.9850\n",
      "Epoch 23/30\n",
      "59400/59400 [==============================] - 40s 675us/step - loss: 0.1760 - acc: 0.9612 - val_loss: 0.1516 - val_acc: 0.9867\n",
      "Epoch 24/30\n",
      "59400/59400 [==============================] - 41s 684us/step - loss: 0.1736 - acc: 0.9615 - val_loss: 0.1650 - val_acc: 0.9833\n",
      "Epoch 25/30\n",
      "59400/59400 [==============================] - 41s 685us/step - loss: 0.1756 - acc: 0.9615 - val_loss: 0.1566 - val_acc: 0.9850\n",
      "Epoch 26/30\n",
      "59400/59400 [==============================] - 40s 678us/step - loss: 0.1752 - acc: 0.9611 - val_loss: 0.1589 - val_acc: 0.9850\n",
      "Epoch 27/30\n",
      "59400/59400 [==============================] - 41s 688us/step - loss: 0.1721 - acc: 0.9629 - val_loss: 0.1577 - val_acc: 0.9850\n",
      "Epoch 28/30\n",
      "59400/59400 [==============================] - 41s 691us/step - loss: 0.1739 - acc: 0.9620 - val_loss: 0.1651 - val_acc: 0.9867\n",
      "Epoch 29/30\n",
      "59400/59400 [==============================] - 40s 681us/step - loss: 0.1768 - acc: 0.9604 - val_loss: 0.1568 - val_acc: 0.9850\n",
      "Epoch 30/30\n",
      "59400/59400 [==============================] - 41s 693us/step - loss: 0.1726 - acc: 0.9618 - val_loss: 0.1460 - val_acc: 0.9883\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 382us/step\n",
      "[0.08548119690418243, 0.9891]\n"
     ]
    }
   ],
   "source": [
    "new_num_epochs = 30\n",
    "\n",
    "history = model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=new_num_epochs,shuffle =True,\n",
    "          verbose=1, validation_split=validation_proba) # ...holding out 10% of the data for validation\n",
    "\n",
    "# EVALUATE THE MODEL ON TEST SET\n",
    "   \n",
    "print(\"\\n EVALUATION [loss, accuracy] on TEST set:\")\n",
    "lossAndAcc = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(lossAndAcc) # Evaluate the trained model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy by epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'valid'], loc='right')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 46s 773us/step - loss: 0.1876 - acc: 0.9586 - val_loss: 0.1637 - val_acc: 0.9833\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 399us/step\n",
      "[0.10148891202807427, 0.9829]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 43s 721us/step - loss: 0.1881 - acc: 0.9576 - val_loss: 0.1720 - val_acc: 0.9817\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 384us/step\n",
      "[0.09644952821731567, 0.9851]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 43s 720us/step - loss: 0.1841 - acc: 0.9587 - val_loss: 0.1553 - val_acc: 0.9850\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 403us/step\n",
      "[0.09831350386738777, 0.9844]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 42s 708us/step - loss: 0.1838 - acc: 0.9593 - val_loss: 0.1485 - val_acc: 0.9867\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 378us/step\n",
      "[0.0984204193174839, 0.9843]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 43s 717us/step - loss: 0.1853 - acc: 0.9590 - val_loss: 0.1609 - val_acc: 0.9850\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 382us/step\n",
      "[0.09708406792879104, 0.9847]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 43s 726us/step - loss: 0.1884 - acc: 0.9579 - val_loss: 0.1635 - val_acc: 0.9867\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 382us/step\n",
      "[0.09623570026755333, 0.9847]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 42s 715us/step - loss: 0.1819 - acc: 0.9593 - val_loss: 0.1605 - val_acc: 0.9800\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 378us/step\n",
      "[0.09818233201503754, 0.9837]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 42s 708us/step - loss: 0.1857 - acc: 0.9587 - val_loss: 0.1570 - val_acc: 0.9867\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 409us/step\n",
      "[0.09687576318979263, 0.9842]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 43s 731us/step - loss: 0.1874 - acc: 0.9570 - val_loss: 0.1661 - val_acc: 0.9783\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 383us/step\n",
      "[0.10366538689136505, 0.9824]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 42s 701us/step - loss: 0.1856 - acc: 0.9584 - val_loss: 0.1675 - val_acc: 0.9800\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 389us/step\n",
      "[0.10047332271933555, 0.9846]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 44s 747us/step - loss: 0.1832 - acc: 0.9592 - val_loss: 0.1529 - val_acc: 0.9867\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 395us/step\n",
      "[0.10259061375260353, 0.9834]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 42s 715us/step - loss: 0.1855 - acc: 0.9583 - val_loss: 0.1409 - val_acc: 0.9883\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 393us/step\n",
      "[0.09638042902350426, 0.9861]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 45s 759us/step - loss: 0.1839 - acc: 0.9589 - val_loss: 0.1529 - val_acc: 0.9850\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 406us/step\n",
      "[0.09954529028534889, 0.9836]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 47s 799us/step - loss: 0.1827 - acc: 0.9596 - val_loss: 0.1599 - val_acc: 0.9817\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 393us/step\n",
      "[0.09805535144805909, 0.9847]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 44s 733us/step - loss: 0.1821 - acc: 0.9592 - val_loss: 0.1595 - val_acc: 0.9817\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 415us/step\n",
      "[0.10211988099813461, 0.983]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 47s 794us/step - loss: 0.1815 - acc: 0.9597 - val_loss: 0.1687 - val_acc: 0.9767\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 422us/step\n",
      "[0.1024097648203373, 0.9833]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 46s 767us/step - loss: 0.1845 - acc: 0.9592 - val_loss: 0.1580 - val_acc: 0.9833\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 5s 455us/step\n",
      "[0.09675854677557945, 0.984]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 46s 772us/step - loss: 0.1858 - acc: 0.9585 - val_loss: 0.1488 - val_acc: 0.9817\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 442us/step\n",
      "[0.09738925681114197, 0.9855]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 48s 805us/step - loss: 0.1856 - acc: 0.9606 - val_loss: 0.1622 - val_acc: 0.9833\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 421us/step\n",
      "[0.10093934032917022, 0.9851]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 46s 779us/step - loss: 0.1828 - acc: 0.9597 - val_loss: 0.1655 - val_acc: 0.9800\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 411us/step\n",
      "[0.10289903523921967, 0.9819]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 51s 866us/step - loss: 0.1861 - acc: 0.9581 - val_loss: 0.1642 - val_acc: 0.9817\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 432us/step\n",
      "[0.10082678110599518, 0.9826]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 47s 791us/step - loss: 0.1845 - acc: 0.9583 - val_loss: 0.1620 - val_acc: 0.9833\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 436us/step\n",
      "[0.10148063406944274, 0.9826]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 51s 851us/step - loss: 0.1876 - acc: 0.9579 - val_loss: 0.1482 - val_acc: 0.9850\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 4s 427us/step\n",
      "[0.10008440082073211, 0.9861]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 48s 815us/step - loss: 0.1815 - acc: 0.9592 - val_loss: 0.1541 - val_acc: 0.9850\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 5s 493us/step\n",
      "[0.10021783354282379, 0.9845]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 53s 896us/step - loss: 0.1830 - acc: 0.9592 - val_loss: 0.1605 - val_acc: 0.9767\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 5s 473us/step\n",
      "[0.09770579069852829, 0.9848]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 49s 828us/step - loss: 0.1816 - acc: 0.9605 - val_loss: 0.1632 - val_acc: 0.9800\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 444us/step\n",
      "[0.1014069131553173, 0.984]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 50s 848us/step - loss: 0.1842 - acc: 0.9599 - val_loss: 0.1661 - val_acc: 0.9833\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 5s 476us/step\n",
      "[0.0983426892876625, 0.9848]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 50s 844us/step - loss: 0.1820 - acc: 0.9594 - val_loss: 0.1598 - val_acc: 0.9800\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 5s 452us/step\n",
      "[0.09665588477849961, 0.9848]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 49s 829us/step - loss: 0.1846 - acc: 0.9589 - val_loss: 0.1396 - val_acc: 0.9867\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 5s 472us/step\n",
      "[0.10347241452932358, 0.9825]\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "59400/59400 [==============================] - 51s 855us/step - loss: 0.1833 - acc: 0.9592 - val_loss: 0.1566 - val_acc: 0.9817\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 5s 454us/step\n",
      "[0.09675001780390739, 0.9841]\n"
     ]
    }
   ],
   "source": [
    "new_num_epochs = 30\n",
    "\n",
    "for epch in range(new_num_epochs):\n",
    "    history = model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=1,shuffle =True,\n",
    "          verbose=1, validation_split=validation_proba) # ...holding out 10% of the data for validation\n",
    "\n",
    "# EVALUATE THE MODEL ON TEST SET\n",
    "   \n",
    "    print(\"\\n EVALUATION [loss, accuracy] on TEST set:\")\n",
    "    lossAndAcc = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    print(lossAndAcc) # Evaluate the trained model on the test set!\n",
    "    if lossAndAcc[1] > 0.99:\n",
    "        print(\"Accuracy := \",lossAndAcc[1],\" in \",(epch+70),\" epochs \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve this result in epochs, with the following parameters : \n",
    "\n",
    "Dropout_rate_1: 0.1, Dropout_rate_2 : 0.1, Weight_penalty: 0.01, Validation_split : 0.01. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to compare this model with another one. For this new model, we add 2 layers of batchNormalization after the convolution/before the activation function. \n",
    "We also twist several parameters such as the conv_depth ( before : (6,16) ---> now : (32,64) ).\n",
    "We could add a third conv layer, but the results I got were pretty similar. \n",
    "\n",
    "With the following parameters :\n",
    "Dropout_rate_1: 0.4, Dropout_rate_2 : 0.4, Weight_penalty: 0.001, Validation_split : 0. \n",
    "num_epochs : \n",
    "\n",
    "\n",
    "We achieve xx.xx% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version tensorflow :1.11.0\n",
      "Version KERAS :2.2.4\n",
      "Checking the shape of our train set : \n",
      "(60000, 1, 28, 28)\n",
      "(60000, 10)\n",
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0xb439584e0>>\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 232s 5ms/step - loss: 0.6486 - acc: 0.8734 - val_loss: 0.2856 - val_acc: 0.9742\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 246s 5ms/step - loss: 0.3559 - acc: 0.9516 - val_loss: 0.2571 - val_acc: 0.9792\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 243s 5ms/step - loss: 0.3247 - acc: 0.9594 - val_loss: 0.2495 - val_acc: 0.9839\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 236s 5ms/step - loss: 0.2995 - acc: 0.9659 - val_loss: 0.2361 - val_acc: 0.9849\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 232s 5ms/step - loss: 0.2828 - acc: 0.9675 - val_loss: 0.2267 - val_acc: 0.9861\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 231s 5ms/step - loss: 0.2653 - acc: 0.9706 - val_loss: 0.2102 - val_acc: 0.9862\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 234s 5ms/step - loss: 0.2539 - acc: 0.9715 - val_loss: 0.2098 - val_acc: 0.9857\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 232s 5ms/step - loss: 0.2501 - acc: 0.9725 - val_loss: 0.1987 - val_acc: 0.9862\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 237s 5ms/step - loss: 0.2375 - acc: 0.9742 - val_loss: 0.2234 - val_acc: 0.9821\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 230s 5ms/step - loss: 0.2289 - acc: 0.9755 - val_loss: 0.1920 - val_acc: 0.9871\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 230s 5ms/step - loss: 0.2284 - acc: 0.9757 - val_loss: 0.1793 - val_acc: 0.9884\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 227s 5ms/step - loss: 0.2235 - acc: 0.9754 - val_loss: 0.1939 - val_acc: 0.9877\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 227s 5ms/step - loss: 0.2176 - acc: 0.9765 - val_loss: 0.1825 - val_acc: 0.9882\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 226s 5ms/step - loss: 0.2135 - acc: 0.9776 - val_loss: 0.1759 - val_acc: 0.9898\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 216s 4ms/step - loss: 0.2160 - acc: 0.9765 - val_loss: 0.1915 - val_acc: 0.9869\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 199s 4ms/step - loss: 0.2084 - acc: 0.9780 - val_loss: 0.1784 - val_acc: 0.9862\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 200s 4ms/step - loss: 0.2060 - acc: 0.9789 - val_loss: 0.1793 - val_acc: 0.9889\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 200s 4ms/step - loss: 0.2082 - acc: 0.9783 - val_loss: 0.1746 - val_acc: 0.9867\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 201s 4ms/step - loss: 0.2027 - acc: 0.9784 - val_loss: 0.1749 - val_acc: 0.9893\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 202s 4ms/step - loss: 0.1991 - acc: 0.9796 - val_loss: 0.1723 - val_acc: 0.9896\n",
      "\n",
      " EVALUATION [loss, accuracy] on TEST set:\n",
      "10000/10000 [==============================] - 15s 1ms/step\n",
      "[0.16857327280044557, 0.9889]\n"
     ]
    }
   ],
   "source": [
    "## We now twist a little bit our model : \n",
    "# ===================================\n",
    "\n",
    "# We add another layer of conv + pooling, using average pooling \n",
    "# We also add Batch Normalization in every conv. layer \n",
    "# Our dense layer is now significantly bigger \n",
    "\n",
    "import os\n",
    "# FIRST CHOOSE WHICH \"BACK-END\" YOU WILL USE, BETWEEN tensorflow (preferable) OR theano\n",
    "#    (depending on which you have managed to install)\n",
    "os.environ['KERAS_BACKEND']=\"tensorflow\"\n",
    "import tensorflow\n",
    "print(\"Version tensorflow :\" + tensorflow.__version__)\n",
    "#os.environ['KERAS_BACKEND']=\"theano\"\n",
    "#import theano\n",
    "#print(\"Version Theano :\" + theano.__version__)\n",
    "\n",
    "\n",
    "# WHATEVER BACK-END YOU HAVE CHOSEN, YOU SHALL USE keras AS RONT-END\n",
    "import keras\n",
    "print(\"Version KERAS :\" + keras.__version__)\n",
    "\n",
    "from keras.datasets import mnist # subroutines for fetching the MNIST dataset\n",
    "from keras.models import Model, Sequential # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv2D,AveragePooling2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "\n",
    "# New Parameters \n",
    "# ==============\n",
    "num_epochs = 20 # we iterate 50 times over the entire training set\n",
    "drop_prob_1 = 0.4# dropout after pooling with probability 1/2\n",
    "drop_prob_2 = 0.4 # dropout in the FC layer with probability 1/2\n",
    "validation_proba = 0.2 # validation_split := 0.1\n",
    "weight_penalty = 0.001 # Factor for weights penalty\n",
    "hidden_size = 128 # the FC layer will have 512 neurons\n",
    "\n",
    "# CONVNET PARAMETERS\n",
    "# ===================\n",
    "batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
    "kernel_size = 5 # we will use 5x5 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 6 kernels in first conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 16 after the first pooling layer\n",
    "\n",
    "\n",
    "\n",
    "# DATASET CHARACTERISTICS\n",
    "num_train = 60000 # there are 60000 training examples in MNIST\n",
    "height, width, depth = 28, 28, 1 # MNIST images are 28x28 and *greyscale*\n",
    "num_classes = 10 # there are 10 classes (1 per digit)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # fetch MNIST data\n",
    "\n",
    "# REFORMAT PROPERLY THE DATA\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 # Normalise data to [0, 1] range\n",
    "X_test /= 255 # Normalise data to [0, 1] range\n",
    "X_train = X_train[:, newaxis, :, :] # Reshape in \"convolutionable\" format (add tensor dim for the depth)\n",
    "X_test = X_test[:, newaxis, :, :] # Reshape in \"convolutionable\" format (add tensor dim for the depth)\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
    "print(\"Checking the shape of our train set : \")\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "\n",
    "# NOW, BUILD THE MODEL ARCHITECTURE\n",
    "# =================================\n",
    "\n",
    "model = Sequential()\n",
    "# FIRST CONVOLUTION+POOLING LAYERS\n",
    "#   Conv [8] -> Pool (with dropout on the pooling layer)\n",
    "model.add( Conv2D(conv_depth_1, (kernel_size,kernel_size), padding='same', activation='linear', \n",
    "                         data_format=\"channels_first\", input_shape=( 1, 28, 28)) )\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add( MaxPooling2D(pool_size=(pool_size, pool_size)) )\n",
    "model.add( Dropout(drop_prob_1) ) # Some Dropout regularization (if necessary)\n",
    "\n",
    "\n",
    "# Third CONVOLUTION+POOLING LAYERS\n",
    "#    Conv [16] -> Pool (with dropout on the pooling layer)\n",
    "model.add( Conv2D(conv_depth_2, (kernel_size,kernel_size), padding='same', activation='linear') )\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add( MaxPooling2D(pool_size=(pool_size, pool_size)) )\n",
    "model.add( Dropout(drop_prob_1) ) # Some Dropout regularization (if necessary)\n",
    "\n",
    "# CLASSIFICATION PART: FULLY-CONNECTED LAYER + OUTPUT LAYER\n",
    "#   Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "model.add( Flatten() )\n",
    "model.add( Dense(hidden_size, activation='relu', kernel_regularizer=regularizers.l2(weight_penalty)) )\n",
    "model.add( Dropout(drop_prob_2) ) # Some Dropout regularization (if necessary)\n",
    "model.add( Dense(num_classes, activation='softmax') )\n",
    "\n",
    "# DISPLAY THE MODEL ARCHITECTURE INFORMATION\n",
    "print(model.summary)\n",
    "\n",
    "# DEFINE THE LOSS FUNCTION AND OPTIMIZER\n",
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "# TRAIN THE MODEL\n",
    "\n",
    "    \n",
    "history = model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, epochs=num_epochs,shuffle =True,\n",
    "          verbose=1, validation_split=validation_proba,\n",
    "           callbacks=[history]) # ...holding out 10% of the data for validation\n",
    "\n",
    "# EVALUATE THE MODEL ON TEST SET\n",
    "   \n",
    "print(\"\\n EVALUATION [loss, accuracy] on TEST set:\")\n",
    "lossAndAcc = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(lossAndAcc) # Evaluate the trained model on the test set!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy by epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'valid'], loc='right')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
